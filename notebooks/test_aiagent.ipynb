{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DataOps Agent Smoke Test\n",
        "Use this notebook to validate your local configuration and exercise the `aiagent` package without leaving Jupyter.\n",
        "It mirrors the CLI workflow so you can debug prompts, inspect settings, and iterate on new tools quickly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "- Install dependencies: `uv venv && source .venv/bin/activate && uv pip install -e \".[dev]\"`.\n",
        "- Copy `.env.example` to `.env`, then fill `LLM_PROVIDER`, model name, and Hugging Face/OpenAI credentials.\n",
        "- (Optional) launch the demo Postgres service with `docker compose up -d postgres` if you want to exercise SQL tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from pathlib import Path\n",
        "\n",
        "# def load_local_env() -> None:\n",
        "#     \"\"\"Load .env files from the repo root when available.\"\"\"\n",
        "#     candidate_roots = [Path.cwd(), Path.cwd().parent]\n",
        "#     env_paths = []\n",
        "#     for root in candidate_roots:\n",
        "#         env_file = (root / '.env').resolve()\n",
        "#         if env_file.exists() and env_file not in env_paths:\n",
        "#             env_paths.append(env_file)\n",
        "#     if not env_paths:\n",
        "#         print('No .env file found; relying on existing environment variables.')\n",
        "#         return\n",
        "#     try:\n",
        "#         from dotenv import load_dotenv  # type: ignore\n",
        "#     except ImportError:\n",
        "#         print('python-dotenv is not installed; skipping automatic .env loading.')\n",
        "#         return\n",
        "#     for env_path in env_paths:\n",
        "#         load_dotenv(env_path)\n",
        "#         print(f'Loaded env vars from {env_path}')\n",
        "\n",
        "# load_local_env()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from aiagent.config import get_settings\n",
        "\n",
        "# settings = get_settings()\n",
        "# settings.model_dump()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from aiagent.agent import build_agent\n",
        "\n",
        "# agent = build_agent(settings)\n",
        "# agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from typing import Any, Dict, List\n",
        "# from langchain_core.messages import HumanMessage\n",
        "\n",
        "# def _message_text(message: Any) -> str | None:\n",
        "#     role = getattr(message, 'type', None)\n",
        "#     content = getattr(message, 'content', None)\n",
        "#     if isinstance(message, dict):\n",
        "#         role = message.get('role') or message.get('type')\n",
        "#         content = message.get('content')\n",
        "#     if role not in {'ai', 'assistant', 'assistant_message'}:\n",
        "#         return None\n",
        "#     if isinstance(content, str):\n",
        "#         text = content.strip()\n",
        "#         return text or None\n",
        "#     if isinstance(content, list):\n",
        "#         parts = []\n",
        "#         for chunk in content:\n",
        "#             if isinstance(chunk, dict) and chunk.get('type') == 'text':\n",
        "#                 text = chunk.get('text')\n",
        "#                 if isinstance(text, str) and text.strip():\n",
        "#                     parts.append(text.strip())\n",
        "#         if parts:\n",
        "#             return '\\n'.join(parts)\n",
        "#     return None\n",
        "\n",
        "# def run_agent_turn(agent, prompt: str, state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "#     messages: List[Any] = list(state.get('messages') or [])\n",
        "#     messages.append(HumanMessage(content=prompt))\n",
        "#     response = agent.invoke({'messages': messages})\n",
        "#     if isinstance(response, dict) and isinstance(response.get('messages'), list):\n",
        "#         messages = response['messages']\n",
        "#     elif isinstance(response, list):\n",
        "#         messages = response\n",
        "#     text = _message_text(messages[-1]) if messages else str(response)\n",
        "#     print(f'Prompt: {prompt}')\n",
        "#     print('---')\n",
        "#     print(text or str(response))\n",
        "#     print()\n",
        "#     state['messages'] = messages\n",
        "#     return state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# state = {'messages': []}\n",
        "# state = run_agent_turn(agent, 'Provide a TL;DR about this agent project.', state)\n",
        "# state = run_agent_turn(agent, 'Now remind me how to launch the CLI.', state)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[35mAgent:\u001b[0m The query returned three users from the database:\n",
            "\n",
            "\u001b[1;36m1\u001b[0m. **User ID:** \u001b[1;36m4\u001b[0m\n",
            "   - **Name:** Alice\n",
            "   - **Email:** alice@example.com\n",
            "   - **Created At:** November \u001b[1;36m9\u001b[0m, \u001b[1;36m2025\u001b[0m, \u001b[1;92m13:59:07\u001b[0m UTC\n",
            "\n",
            "\u001b[1;36m2\u001b[0m. **User ID:** \u001b[1;36m5\u001b[0m\n",
            "   - **Name:** Bob\n",
            "   - **Email:** bob@example.com\n",
            "   - **Created At:** November \u001b[1;36m9\u001b[0m, \u001b[1;36m2025\u001b[0m, \u001b[1;92m13:59:07\u001b[0m UTC\n",
            "\n",
            "\u001b[1;36m3\u001b[0m. **User ID:** \u001b[1;36m6\u001b[0m\n",
            "   - **Name:** Carol\n",
            "   - **Email:** carol@example.com\n",
            "   - **Created At:** November \u001b[1;36m9\u001b[0m, \u001b[1;36m2025\u001b[0m, \u001b[1;92m13:59:07\u001b[0m UTC\n",
            "\n",
            "If you need further analysis or specific information about these users, let me \n",
            "know!\n"
          ]
        }
      ],
      "source": [
        "RUN_CLI_COMMAND = True\n",
        "\n",
        "if RUN_CLI_COMMAND:\n",
        "    import subprocess\n",
        "    subprocess.run(\n",
        "        ['python', '-m', 'aiagent.cli', 'select * from users'],\n",
        "        check=True,\n",
        "    )\n",
        "else:\n",
        "    print('Set RUN_CLI_COMMAND=True to exercise the Typer CLI from this notebook.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9962d7fd",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dataops-agent (3.12.11)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
